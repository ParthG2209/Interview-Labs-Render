import formidable from 'formidable';
import fs from 'fs';

export const config = {
  api: {
    bodyParser: false,
  },
  maxDuration: 300, // 5 minutes for real transcription
};

export default async function handler(req, res) {
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
    
    if (req.method === 'OPTIONS') return res.status(200).end();
    if (req.method !== 'POST') return res.status(405).json({ error: 'Method not allowed' });

    try {
        console.log('üìπ Starting real video transcription analysis...');
        
        const form = formidable({
            maxFileSize: 50 * 1024 * 1024,
            filter: ({ mimetype }) => mimetype && mimetype.startsWith('video/'),
        });

        const [fields, files] = await form.parse(req);
        const field = fields.field?.[0] || 'general';
        const videoFile = files.video?.[0];

        if (!videoFile) {
            return res.status(400).json({
                analysis: {
                    rating: 0,
                    mistakes: [{ timestamp: '0:00', text: 'No video file uploaded' }],
                    tips: ['Upload a video file for real transcription analysis'],
                    summary: 'Please upload a video file'
                },
                success: false,
                actualVideoProcessed: false
            });
        }

        console.log('üé¨ Processing video:', {
            name: videoFile.originalFilename,
            size: `${Math.round(videoFile.size / (1024 * 1024) * 10) / 10}MB`,
            type: videoFile.mimetype,
            field: field
        });

        // Get REAL transcription using AssemblyAI
        console.log('üé§ Starting real transcription...');
        const transcription = await getRealTranscription(videoFile);
        
        if (transcription.error) {
            console.log('‚ùå Transcription failed, using smart file analysis');
            // Fallback to smart file-based analysis
            const analysis = generateSmartVideoAnalysis(field, videoFile);
            
            // Cleanup
            if (fs.existsSync(videoFile.filepath)) {
                fs.unlinkSync(videoFile.filepath);
            }

            return res.json({
                analysis: {
                    ...analysis,
                    summary: analysis.summary + ' (Transcription service unavailable - using smart file analysis)'
                },
                success: true,
                processed: true,
                actualVideoProcessed: false,
                source: 'SMART-FILE-ANALYSIS',
                transcriptionError: transcription.error
            });
        }

        console.log('‚úÖ Real transcription complete:', transcription.text?.substring(0, 100) + '...');

        // Analyze REAL speech content
        const analysis = await analyzeRealSpeech(transcription, field);

        // Cleanup
        if (fs.existsSync(videoFile.filepath)) {
            fs.unlinkSync(videoFile.filepath);
        }

        return res.json({
            analysis,
            success: true,
            processed: true,
            actualVideoProcessed: true,
            source: 'REAL-SPEECH-TRANSCRIPTION',
            transcriptionPreview: transcription.text.substring(0, 150) + '...',
            speechMetrics: {
                wordCount: transcription.text.split(' ').length,
                duration: transcription.duration || 'estimated',
                confidence: transcription.confidence || 'N/A'
            }
        });

    } catch (error) {
        console.error('‚ùå Video analysis error:', error);
        
        // Cleanup on error
        try {
            if (req.files?.video?.[0]?.filepath && fs.existsSync(req.files.video[0].filepath)) {
                fs.unlinkSync(req.files.video[0].filepath);
            }
        } catch (cleanupError) {
            console.warn('Cleanup error:', cleanupError.message);
        }

        return res.status(500).json({
            error: 'Analysis failed',
            message: 'Video analysis failed: ' + error.message,
            details: error.stack
        });
    }
}

// Fixed version - works on Vercel
async function getRealTranscription(videoFile) {
    const apiKey = process.env.ASSEMBLYAI_API_KEY;
    
    if (!apiKey) {
        return { error: 'No transcription API key configured' };
    }

    try {
        console.log('üé§ Uploading video to AssemblyAI...');
        
        // Read file as buffer (instead of stream for Vercel compatibility)
        const fileBuffer = fs.readFileSync(videoFile.filepath);
        
        // Upload video file with proper options for Vercel
        const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
            method: 'POST',
            headers: { 
                'Authorization': apiKey,
                'Content-Type': 'application/octet-stream'
            },
            body: fileBuffer,
            duplex: 'half' // Required for Vercel
        });

        if (!uploadResponse.ok) {
            const errorText = await uploadResponse.text();
            throw new Error(`Upload failed: ${uploadResponse.status} ${errorText}`);
        }

        const { upload_url } = await uploadResponse.json();
        console.log('üì§ Video uploaded, starting transcription...');

        // Request transcription
        const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
            method: 'POST',
            headers: {
                'Authorization': apiKey,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                audio_url: upload_url,
                speaker_labels: true,
                language_code: 'en',
                punctuate: true,
                format_text: true
            })
        });

        if (!transcriptResponse.ok) {
            const errorText = await transcriptResponse.text();
            throw new Error(`Transcription request failed: ${transcriptResponse.status} ${errorText}`);
        }

        const { id } = await transcriptResponse.json();
        console.log('‚è≥ Transcription in progress, ID:', id);

        // Poll for completion (with timeout)
        let transcript;
        let attempts = 0;
        const maxAttempts = 100; // ~5 minutes max
        
        do {
            await new Promise(resolve => setTimeout(resolve, 3000));
            
            const pollingResponse = await fetch(`https://api.assemblyai.com/v2/transcript/${id}`, {
                headers: { 'Authorization': apiKey }
            });
            
            if (!pollingResponse.ok) {
                throw new Error(`Polling failed: ${pollingResponse.status}`);
            }
            
            transcript = await pollingResponse.json();
            console.log(`üìä Transcription status: ${transcript.status} (attempt ${attempts + 1}/${maxAttempts})`);
            
            attempts++;
        } while ((transcript.status === 'processing' || transcript.status === 'queued') && attempts < maxAttempts);

        if (transcript.status === 'completed') {
            console.log('‚úÖ Real transcription successful!');
            console.log('üìù Transcript preview:', transcript.text?.substring(0, 100) + '...');
            
            return {
                text: transcript.text || '',
                duration: transcript.audio_duration || 0,
                confidence: transcript.confidence || 0,
                segments: transcript.utterances?.map(u => ({
                    start: u.start / 1000,
                    end: u.end / 1000,
                    text: u.text,
                    speaker: u.speaker,
                    confidence: u.confidence
                })) || []
            };
        } else if (transcript.status === 'error') {
            throw new Error(`Transcription failed: ${transcript.error || 'Unknown error'}`);
        } else {
            throw new Error(`Transcription timed out after ${maxAttempts} attempts`);
        }

    } catch (error) {
        console.error('‚ùå AssemblyAI error:', error);
        return { 
            error: 'Transcription service error: ' + error.message,
            details: error.stack
        };
    }
}

// Analyze REAL speech content (like your local Cohere analysis)
async function analyzeRealSpeech(transcription, field) {
    const text = transcription.text;
    const wordCount = text.split(' ').length;
    
    console.log('üß† Analyzing real speech:', { wordCount, field });

    // Check for empty/minimal speech
    if (wordCount < 5) {
        return {
            rating: 0,
            mistakes: [{
                timestamp: '0:05',
                text: 'No meaningful speech detected - please speak clearly into the microphone'
            }],
            tips: [
                'Ensure you are actually speaking during the recording',
                'Check microphone permissions and audio levels',
                'Speak clearly and at normal volume',
                'Record in a quiet environment'
            ],
            summary: 'No speech content detected for analysis. Please record again with clear audio.'
        };
    }

    if (wordCount < 20) {
        return {
            rating: 2,
            mistakes: [{
                timestamp: '0:10',
                text: 'Response too brief - provide more detailed answers with specific examples'
            }],
            tips: [
                'Elaborate on your experience with concrete examples',
                'Use the STAR method (Situation, Task, Action, Result)',
                'Aim for 1-2 minutes per response',
                'Include specific technologies and metrics'
            ],
            summary: `Brief response detected (${wordCount} words). Expand your answers for better evaluation.`
        };
    }

    // REAL content analysis
    const technicalTerms = (text.match(/\b(javascript|react|node|python|java|database|api|system|software|code|programming|development|framework|library|algorithm|data|server|frontend|backend|fullstack|git|docker|aws|cloud|microservices|testing|debugging|deployment|scalability|performance|security|architecture|html|css|typescript|angular|vue|spring|hibernate|mysql|postgresql|mongodb|redis|kubernetes|devops|ci|cd|agile|scrum)\b/gi) || []).length;

    const confidenceWords = (text.match(/\b(successfully|achieved|led|implemented|improved|optimized|designed|developed|managed|created|built|delivered|solved|experience|expertise|proficient|skilled|accomplished|responsible|contributed|collaborated|completed|established|enhanced|streamlined|automated|integrated|architected)\b/gi) || []).length;

    const fillerWords = (text.match(/\b(um|uh|like|you know|actually|basically|sort of|kind of|well|so|right|okay|yeah|hmm|er|ah)\b/gi) || []).length;

    const specificMetrics = (text.match(/\b(\d+%|\d+\s*(percent|times|years|months|weeks|days|users|customers|projects|team|members|million|thousand|hours|dollars|revenue|growth|reduction|increase|decrease|improvement))\b/gi) || []).length;

    const questionWords = (text.match(/\b(what|how|why|when|where|which|who|could you|can you|would you|do you|have you|will you)\b/gi) || []).length;

    console.log('üìä Real speech analysis:', {
        wordCount,
        technicalTerms,
        confidenceWords,
        fillerWords,
        specificMetrics,
        questionWords
    });

    // Calculate rating based on REAL speech analysis
    let rating = 4; // Base
    
    if (wordCount > 50) rating += 1; // Good length
    if (wordCount > 100) rating += 0.5; // Comprehensive
    if (technicalTerms > 2) rating += 1; // Technical depth
    if (technicalTerms > 5) rating += 0.5; // Strong technical vocabulary
    if (confidenceWords > 2) rating += 1; // Confident language
    if (confidenceWords > 4) rating += 0.5; // Very confident
    if (specificMetrics > 0) rating += 1; // Quantifiable results
    if (specificMetrics > 2) rating += 0.5; // Multiple metrics
    if (fillerWords < wordCount / 20) rating += 0.5; // Clear speech
    if (questionWords > 0) rating += 0.5; // Engagement
    
    // Field-specific bonuses
    const fieldLower = field.toLowerCase();
    if (fieldLower.includes('senior') && technicalTerms > 4) rating += 0.5;
    if (fieldLower.includes('intern') && confidenceWords > 1) rating += 0.5;
    if (fieldLower.includes('java') && text.toLowerCase().includes('java')) rating += 0.5;
    
    rating = Math.min(9, Math.max(1, Math.round(rating * 2) / 2));

    // Generate specific mistakes based on real content
    const mistakes = [];
    
    if (fillerWords > wordCount / 15) {
        const fillerPercent = Math.round((fillerWords / wordCount) * 100);
        mistakes.push({
            timestamp: findFillerTimestamp(transcription.segments, fillerWords),
            text: `Reduce filler words (${fillerPercent}% of speech) - practice speaking more deliberately`
        });
    }

    if (specificMetrics === 0 && wordCount > 30) {
        mistakes.push({
            timestamp: '1:30',
            text: 'Include specific metrics and quantifiable achievements in your examples'
        });
    }

    if (technicalTerms < 2 && wordCount > 30) {
        mistakes.push({
            timestamp: '2:00',
            text: `Use more ${field}-specific technical terminology to demonstrate expertise`
        });
    }

    if (confidenceWords < 2 && wordCount > 40) {
        mistakes.push({
            timestamp: '1:45',
            text: 'Use more confident, achievement-oriented language when describing your experience'
        });
    }

    if (wordCount < 40) {
        mistakes.push({
            timestamp: '0:30',
            text: 'Provide more comprehensive responses with detailed examples and context'
        });
    }

    // Generate real content-based tips
    const tips = [
        `Real speech analysis: ${wordCount} words, ${technicalTerms} technical terms, ${confidenceWords} confidence indicators`,
        technicalTerms > 3 ? 'Excellent technical vocabulary usage' : `Include more ${field}-specific technical concepts and terminology`,
        confidenceWords > 2 ? 'Strong confident communication style detected' : 'Practice using more achievement-focused language',
        specificMetrics > 0 ? 'Good use of quantifiable results' : 'Always include specific numbers and measurable outcomes',
        fillerWords < wordCount / 25 ? 'Clear, fluent speech patterns' : 'Practice reducing filler words for more professional delivery'
    ];

    return {
        rating,
        mistakes: mistakes.slice(0, 3),
        tips: tips.slice(0, 5),
        summary: `Real speech transcription analysis: ${wordCount} words analyzed. Technical terms: ${technicalTerms}, Confidence indicators: ${confidenceWords}, Filler words: ${fillerWords}. Rating: ${rating}/10. ${rating >= 7 ? 'Strong interview performance with clear technical communication.' : rating >= 5 ? 'Good foundation with specific areas for improvement based on actual speech content.' : 'Focus on the identified areas to significantly enhance interview performance.'}`
    };
}

// Enhanced smart analysis fallback (when transcription fails)
function generateSmartVideoAnalysis(field, videoFile) {
    const fileSize = videoFile.size;
    const fileName = videoFile.originalFilename || 'video.mp4';
    const mimeType = videoFile.mimetype;
    
    // Estimate video duration more accurately
    let estimatedDurationSeconds = 30;
    
    if (mimeType.includes('webm')) {
        if (fileSize > 5 * 1024 * 1024) {
            estimatedDurationSeconds = Math.max(30, Math.min(300, fileSize / (1024 * 60)));
        } else {
            estimatedDurationSeconds = Math.max(10, Math.min(180, fileSize / (1024 * 100)));
        }
    } else if (mimeType.includes('mp4')) {
        estimatedDurationSeconds = Math.max(15, Math.min(300, fileSize / (1024 * 80)));
    }

    console.log('‚è±Ô∏è Smart Duration Analysis:', {
        estimatedSeconds: estimatedDurationSeconds.toFixed(1),
        sizeMB: (fileSize / (1024 * 1024)).toFixed(1),
        type: mimeType
    });

    // Check for obviously unusable videos
    if (estimatedDurationSeconds < 10) {
        return {
            rating: 0,
            mistakes: [{
                timestamp: '0:05',
                text: 'Video too short for meaningful analysis (minimum 15 seconds of speech required)'
            }],
            tips: [
                'Record yourself actually answering the interview questions',
                'Speak for at least 15-30 seconds per response',
                'Provide specific examples and details in your answers',
                'Ensure you are speaking clearly into the microphone'
            ],
            summary: `Video appears to be ${estimatedDurationSeconds.toFixed(1)} seconds - too brief for interview analysis. Please record a proper response.`
        };
    }

    // Create file-based hash for consistency
    let hash = 0;
    const hashInput = fileName + fileSize.toString() + field + estimatedDurationSeconds.toString();
    for (let i = 0; i < hashInput.length; i++) {
        hash = ((hash << 5) - hash) + hashInput.charCodeAt(i);
        hash = hash & hash;
    }
    const fileHash = Math.abs(hash);

    // Smart rating based on multiple factors
    let baseRating = 6;
    
    // Field-specific base ratings
    const fieldLower = field.toLowerCase();
    if (fieldLower.includes('senior') || fieldLower.includes('lead')) baseRating = 7;
    else if (fieldLower.includes('java') || fieldLower.includes('python')) baseRating = 6.5;
    else if (fieldLower.includes('intern') || fieldLower.includes('entry')) baseRating = 5;
    else if (fieldLower.includes('frontend') || fieldLower.includes('ui')) baseRating = 6;

    // Duration-based adjustments
    if (estimatedDurationSeconds >= 60) baseRating += 0.5;
    if (estimatedDurationSeconds >= 120) baseRating += 0.5;
    if (estimatedDurationSeconds >= 180) baseRating += 0.5;
    if (estimatedDurationSeconds < 30) baseRating -= 1;
    if (estimatedDurationSeconds > 300) baseRating -= 0.5;

    // File quality indicators
    const sizeMB = fileSize / (1024 * 1024);
    const qualityRatio = sizeMB / (estimatedDurationSeconds / 60);
    
    if (qualityRatio > 3) baseRating += 0.25;
    if (qualityRatio > 5) baseRating += 0.25;
    if (qualityRatio < 0.5) baseRating -= 0.25;

    // Consistent variation based on file properties
    const hashVariation = ((fileHash % 10) - 5) * 0.15;
    const finalRating = Math.max(1, Math.min(9, baseRating + hashVariation));
    const rating = Math.round(finalRating * 4) / 4;

    // Generate duration-appropriate mistakes
    const mistakes = [];
    
    if (estimatedDurationSeconds < 45) {
        mistakes.push({
            timestamp: '0:30',
            text: 'Provide more comprehensive responses - aim for 1-2 minutes per answer with specific examples'
        });
    }
    
    if (estimatedDurationSeconds > 240) {
        mistakes.push({
            timestamp: '3:30',
            text: 'Consider being more concise - focus on the most impactful points and key achievements'
        });
    }

    // Field and performance-based feedback
    const mistakePool = [
        { timestamp: '0:45', text: `Include more specific ${field} technologies and frameworks you've worked with` },
        { timestamp: '1:20', text: 'Provide quantifiable metrics and measurable outcomes from your experience' },
        { timestamp: '1:50', text: 'Use more confident language when describing your technical abilities' },
        { timestamp: '2:15', text: 'Structure responses using STAR method (Situation, Task, Action, Result)' },
        { timestamp: '1:35', text: 'Maintain better eye contact with the camera throughout your response' }
    ];

    // Select mistakes based on rating and file hash
    const numMistakes = rating >= 8 ? 1 : rating >= 6.5 ? 2 : 3;
    for (let i = 0; i < numMistakes && mistakes.length < 3; i++) {
        const index = (fileHash + i * 3) % mistakePool.length;
        if (!mistakes.some(m => m.text === mistakePool[index].text)) {
            mistakes.push(mistakePool[index]);
        }
    }

    // Smart tips based on analysis
    const durationMinutes = (estimatedDurationSeconds / 60).toFixed(1);
    
    const tips = [
        `Smart video analysis: ${durationMinutes} minute response (${sizeMB.toFixed(1)}MB, ${qualityRatio.toFixed(1)}MB/min)`,
        rating >= 7 ? 'Strong foundation - focus on fine-tuning delivery and examples' : 'Build confidence through practice with mock interview questions',
        estimatedDurationSeconds >= 60 ? 'Good response length - ensure all time is used effectively' : 'Expand responses with more detailed examples and explanations',
        `For ${field} roles, research common technical questions and prepare 3-4 detailed STAR examples`,
        qualityRatio > 2 ? 'Excellent video quality detected' : 'Consider improving lighting and audio quality for better presentation'
    ];

    return {
        rating,
        mistakes,
        tips,
        summary: `Smart video analysis for ${field} position: ${durationMinutes} minutes of estimated content. Quality ratio: ${qualityRatio.toFixed(1)}MB/min. Overall performance: ${rating}/10. ${rating >= 7 ? 'Strong interview readiness with targeted improvement areas.' : rating >= 5 ? 'Good potential with specific development opportunities.' : 'Focus on building confidence and expanding response depth.'}`
    };
}

function findFillerTimestamp(segments, fillerCount) {
    if (!segments || segments.length === 0) return '1:15';
    
    // Find a segment that likely contains filler words
    const midPoint = Math.floor(segments.length / 2);
    const segment = segments[midPoint];
    const minutes = Math.floor(segment.start / 60);
    const seconds = Math.floor(segment.start % 60);
    return `${minutes}:${seconds.toString().padStart(2, '0')}`;
}
